Time: 2019-08-04 11:17:52.511276
model_name: UNet
train_df_name: train.csv
resume: False
pretrained: False
pretrained_path: weights//ckpt31.pth
folder: weights/48_UNet_f1_test
fold: 1
total_folds: 5
num_samples: None
sampling class weights: None
size: 512
top_lr: 0.0005
base_lr: None
num_workers: 12
batchsize: {'train': 16, 'val': 8}
momentum: 0.95
mean: (0.485, 0.456, 0.406)
std: (0.229, 0.224, 0.225)
start_epoch: 0
augmentations: [HorizontalFlip(always_apply=False, p=0.5), ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0, 0), scale_limit=(-0.09999999999999998, 0.10000000000000009), rotate_limit=(-10, 10), interpolation=1, border_mode=0, value=None), Normalize(always_apply=False, p=1, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensor(always_apply=True, p=1.0, num_classes=1, sigmoid=True, normalize=None)]
criterion: MixedLoss(
  (focal): FocalLoss()
)
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
)
remark: 
Time: 2019-08-04 11:21:29.198343
model_name: UNet
train_df_name: train.csv
resume: False
pretrained: False
pretrained_path: weights//ckpt31.pth
folder: weights/48_UNet_f1_test
fold: 1
total_folds: 5
num_samples: None
sampling class weights: None
size: 512
top_lr: 0.0005
base_lr: None
num_workers: 12
batchsize: {'train': 16, 'val': 8}
momentum: 0.95
mean: (0.485, 0.456, 0.406)
std: (0.229, 0.224, 0.225)
start_epoch: 0
augmentations: [HorizontalFlip(always_apply=False, p=0.5), ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0, 0), scale_limit=(-0.09999999999999998, 0.10000000000000009), rotate_limit=(-10, 10), interpolation=1, border_mode=0, value=None), Normalize(always_apply=False, p=1, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensor(always_apply=True, p=1.0, num_classes=1, sigmoid=True, normalize=None)]
criterion: MixedLoss(
  (focal): FocalLoss()
)
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
)
remark: 
Time: 2019-08-04 11:22:01.528713
model_name: UNet
train_df_name: train.csv
resume: False
pretrained: False
pretrained_path: weights//ckpt31.pth
folder: weights/48_UNet_f1_test
fold: 1
total_folds: 5
num_samples: None
sampling class weights: None
size: 512
top_lr: 0.0005
base_lr: None
num_workers: 12
batchsize: {'train': 16, 'val': 8}
momentum: 0.95
mean: (0.485, 0.456, 0.406)
std: (0.229, 0.224, 0.225)
start_epoch: 0
augmentations: [HorizontalFlip(always_apply=False, p=0.5), ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0, 0), scale_limit=(-0.09999999999999998, 0.10000000000000009), rotate_limit=(-10, 10), interpolation=1, border_mode=0, value=None), Normalize(always_apply=False, p=1, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensor(always_apply=True, p=1.0, num_classes=1, sigmoid=True, normalize=None)]
criterion: MixedLoss(
  (focal): FocalLoss()
)
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
)
remark: 
Time: 2019-08-04 11:28:48.493239
model_name: UNet
train_df_name: train.csv
resume: False
pretrained: False
pretrained_path: weights//ckpt31.pth
folder: weights/48_UNet_f1_test
fold: 1
total_folds: 5
num_samples: None
sampling class weights: None
size: 512
top_lr: 0.0005
base_lr: None
num_workers: 12
batchsize: {'train': 16, 'val': 8}
momentum: 0.95
mean: (0.485, 0.456, 0.406)
std: (0.229, 0.224, 0.225)
start_epoch: 0
augmentations: [HorizontalFlip(always_apply=False, p=0.5), ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0, 0), scale_limit=(-0.09999999999999998, 0.10000000000000009), rotate_limit=(-10, 10), interpolation=1, border_mode=0, value=None), Normalize(always_apply=False, p=1, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensor(always_apply=True, p=1.0, num_classes=1, sigmoid=True, normalize=None)]
criterion: MixedLoss(
  (focal): FocalLoss()
)
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
)
remark: 
Time: 2019-08-04 11:36:05.564122
model_name: UNet
train_df_name: train.csv
resume: False
pretrained: False
pretrained_path: weights//ckpt31.pth
folder: weights/48_UNet_f1_test
fold: 1
total_folds: 5
num_samples: None
sampling class weights: None
size: 512
top_lr: 0.0005
base_lr: None
num_workers: 12
batchsize: {'train': 16, 'val': 8}
momentum: 0.95
mean: (0.485, 0.456, 0.406)
std: (0.229, 0.224, 0.225)
start_epoch: 0
augmentations: [HorizontalFlip(always_apply=False, p=0.5), ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0, 0), scale_limit=(-0.09999999999999998, 0.10000000000000009), rotate_limit=(-10, 10), interpolation=1, border_mode=0, value=None), Normalize(always_apply=False, p=1, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensor(always_apply=True, p=1.0, num_classes=1, sigmoid=True, normalize=None)]
criterion: MixedLoss(
  (focal): FocalLoss()
)
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
)
remark: 
Time: 2019-08-04 11:38:38.318508
model_name: UNet
train_df_name: train.csv
resume: False
pretrained: False
pretrained_path: weights//ckpt31.pth
folder: weights/48_UNet_f1_test
fold: 1
total_folds: 5
num_samples: None
sampling class weights: None
size: 512
top_lr: 0.0005
base_lr: None
num_workers: 12
batchsize: {'train': 16, 'val': 8}
momentum: 0.95
mean: (0.485, 0.456, 0.406)
std: (0.229, 0.224, 0.225)
start_epoch: 0
augmentations: [HorizontalFlip(always_apply=False, p=0.5), ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0, 0), scale_limit=(-0.09999999999999998, 0.10000000000000009), rotate_limit=(-10, 10), interpolation=1, border_mode=0, value=None), Normalize(always_apply=False, p=1, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensor(always_apply=True, p=1.0, num_classes=1, sigmoid=True, normalize=None)]
criterion: MixedLoss(
  (focal): FocalLoss()
)
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
)
remark: 
Time: 2019-08-04 11:41:39.421221
model_name: UNet
train_df_name: train.csv
resume: False
pretrained: False
pretrained_path: weights//ckpt31.pth
folder: weights/48_UNet_f1_test
fold: 1
total_folds: 5
num_samples: None
sampling class weights: None
size: 512
top_lr: 0.0005
base_lr: None
num_workers: 12
batchsize: {'train': 16, 'val': 8}
momentum: 0.95
mean: (0.485, 0.456, 0.406)
std: (0.229, 0.224, 0.225)
start_epoch: 0
augmentations: [HorizontalFlip(always_apply=False, p=0.5), ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0, 0), scale_limit=(-0.09999999999999998, 0.10000000000000009), rotate_limit=(-10, 10), interpolation=1, border_mode=0, value=None), Normalize(always_apply=False, p=1, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensor(always_apply=True, p=1.0, num_classes=1, sigmoid=True, normalize=None)]
criterion: MixedLoss(
  (focal): FocalLoss()
)
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
)
remark: 
Time: 2019-08-04 11:45:04.374483
model_name: UNet
train_df_name: train.csv
resume: False
pretrained: False
pretrained_path: weights//ckpt31.pth
folder: weights/48_UNet_f1_test
fold: 1
total_folds: 5
num_samples: None
sampling class weights: None
size: 512
top_lr: 0.0005
base_lr: None
num_workers: 12
batchsize: {'train': 16, 'val': 8}
momentum: 0.95
mean: (0.485, 0.456, 0.406)
std: (0.229, 0.224, 0.225)
start_epoch: 0
augmentations: [HorizontalFlip(always_apply=False, p=0.5), ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0, 0), scale_limit=(-0.09999999999999998, 0.10000000000000009), rotate_limit=(-10, 10), interpolation=1, border_mode=0, value=None), Normalize(always_apply=False, p=1, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensor(always_apply=True, p=1.0, num_classes=1, sigmoid=True, normalize=None)]
criterion: MixedLoss(
  (focal): FocalLoss()
)
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
)
remark: 
Time: 2019-08-04 11:45:46.985910
model_name: UNet
train_df_name: train.csv
resume: False
pretrained: False
pretrained_path: weights//ckpt31.pth
folder: weights/48_UNet_f1_test
fold: 1
total_folds: 5
num_samples: None
sampling class weights: None
size: 512
top_lr: 0.0005
base_lr: None
num_workers: 12
batchsize: {'train': 16, 'val': 8}
momentum: 0.95
mean: (0.485, 0.456, 0.406)
std: (0.229, 0.224, 0.225)
start_epoch: 0
augmentations: [HorizontalFlip(always_apply=False, p=0.5), ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0, 0), scale_limit=(-0.09999999999999998, 0.10000000000000009), rotate_limit=(-10, 10), interpolation=1, border_mode=0, value=None), Normalize(always_apply=False, p=1, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensor(always_apply=True, p=1.0, num_classes=1, sigmoid=True, normalize=None)]
criterion: MixedLoss(
  (focal): FocalLoss()
)
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
)
remark: 
Time: 2019-08-04 11:47:45.449724
model_name: UNet
train_df_name: train.csv
resume: False
pretrained: False
pretrained_path: weights//ckpt31.pth
folder: weights/48_UNet_f1_test
fold: 1
total_folds: 5
num_samples: None
sampling class weights: None
size: 512
top_lr: 0.0005
base_lr: None
num_workers: 12
batchsize: {'train': 16, 'val': 8}
momentum: 0.95
mean: (0.485, 0.456, 0.406)
std: (0.229, 0.224, 0.225)
start_epoch: 0
augmentations: [HorizontalFlip(always_apply=False, p=0.5), ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0, 0), scale_limit=(-0.09999999999999998, 0.10000000000000009), rotate_limit=(-10, 10), interpolation=1, border_mode=0, value=None), Normalize(always_apply=False, p=1, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensor(always_apply=True, p=1.0, num_classes=1, sigmoid=True, normalize=None)]
criterion: MixedLoss(
  (focal): FocalLoss()
)
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
)
remark: 
Time: 2019-08-04 11:51:05.329632
model_name: UNet
train_df_name: train.csv
resume: False
pretrained: False
pretrained_path: weights//ckpt31.pth
folder: weights/48_UNet_f1_test
fold: 1
total_folds: 5
num_samples: None
sampling class weights: None
size: 512
top_lr: 0.0005
base_lr: None
num_workers: 12
batchsize: {'train': 16, 'val': 8}
momentum: 0.95
mean: (0.485, 0.456, 0.406)
std: (0.229, 0.224, 0.225)
start_epoch: 0
augmentations: [HorizontalFlip(always_apply=False, p=0.5), ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0, 0), scale_limit=(-0.09999999999999998, 0.10000000000000009), rotate_limit=(-10, 10), interpolation=1, border_mode=0, value=None), Normalize(always_apply=False, p=1, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensor(always_apply=True, p=1.0, num_classes=1, sigmoid=True, normalize=None)]
criterion: MixedLoss(
  (focal): FocalLoss()
)
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.0005
    weight_decay: 0
)
remark: 
Time: 2019-08-04 19:39:03.781253
model_name: UNet
train_df_name: train.csv
resume: True
pretrained: False
pretrained_path: weights//ckpt31.pth
folder: weights/48_UNet_f1_test
fold: 1
total_folds: 5
num_samples: None
sampling class weights: None
size: 1024
top_lr: 5e-05
base_lr: None
num_workers: 12
batchsize: {'train': 4, 'val': 2}
momentum: 0.95
mean: (0.485, 0.456, 0.406)
std: (0.229, 0.224, 0.225)
start_epoch: 39
augmentations: [HorizontalFlip(always_apply=False, p=0.5), ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0, 0), scale_limit=(-0.09999999999999998, 0.10000000000000009), rotate_limit=(-10, 10), interpolation=1, border_mode=0, value=None), Normalize(always_apply=False, p=1, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensor(always_apply=True, p=1.0, num_classes=1, sigmoid=True, normalize=None)]
criterion: MixedLoss(
  (focal): FocalLoss()
)
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
)
remark: 
Time: 2019-08-04 19:43:23.997892
model_name: UNet
train_df_name: train.csv
resume: True
pretrained: False
pretrained_path: weights//ckpt31.pth
folder: weights/48_UNet_f1_test
fold: 1
total_folds: 5
num_samples: None
sampling class weights: None
size: 1024
top_lr: 5e-05
base_lr: None
num_workers: 12
batchsize: {'train': 4, 'val': 2}
momentum: 0.95
mean: (0.485, 0.456, 0.406)
std: (0.229, 0.224, 0.225)
start_epoch: 39
augmentations: [HorizontalFlip(always_apply=False, p=0.5), ShiftScaleRotate(always_apply=False, p=0.5, shift_limit=(0, 0), scale_limit=(-0.09999999999999998, 0.10000000000000009), rotate_limit=(-10, 10), interpolation=1, border_mode=0, value=None), Normalize(always_apply=False, p=1, mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0), ToTensor(always_apply=True, p=1.0, num_classes=1, sigmoid=True, normalize=None)]
criterion: MixedLoss(
  (focal): FocalLoss()
)
optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 1e-05
    weight_decay: 0
)
remark: 
